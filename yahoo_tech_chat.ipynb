{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "twEgdBbkAH8e",
        "outputId": "8ae0f730-e78f-4db8-ca64-9ebe14f470ce"
      },
      "outputs": [],
      "source": [
        "# Step 1: Install and Import Dependencies\n",
        "!pip install sentence-transformers datasets gradio nltk numpy torch networkx scikit-learn pandas\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaRfu0eQB1bY",
        "outputId": "67f560cc-ef2d-4c32-c9f2-8cd8523779e1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import nltk\n",
        "import networkx as nx\n",
        "import gradio as gr\n",
        "import pandas as pd\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from nltk.tokenize import word_tokenize\n",
        "from datasets import load_dataset\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2sY0GdSsBnR"
      },
      "source": [
        "#### Load and Preprocess Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJ9Q_AcFB50l",
        "outputId": "2a42deef-22c4-4ffe-c2a1-81d524155826"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset(\"yahoo_answers_qa\")\n",
        "tech_categories = [\"Computers & Internet\", \"Consumer Electronics\", \"Yahoo! Products\"]\n",
        "tech_dataset = dataset['train'].filter(lambda x: x['main_category'] in tech_categories)\n",
        "tech_dataset = tech_dataset.select(range(5000))  # Limit to 5,000 entries\n",
        "print(f\"Loaded {len(tech_dataset)} tech-related entries\")\n",
        "\n",
        "questions = [q['question'] for q in tech_dataset]\n",
        "answers = [q['answer'] for q in tech_dataset]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Huu1fEcvsjC7"
      },
      "source": [
        "#### Create Embeddings Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnznjtQ7Jpkl",
        "outputId": "8c56e7bb-b6d8-4409-82e2-1e5deb1ac7d7"
      },
      "outputs": [],
      "source": [
        "print(\"Initializing model...\")\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "print(\"Computing embeddings...\")\n",
        "doc_embeddings = model.encode(answers, convert_to_tensor=True)\n",
        "print(\"Embeddings computed successfully!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srbi1SJzstcp"
      },
      "source": [
        "### Implement Context Retention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aH5wssqEB8aa"
      },
      "outputs": [],
      "source": [
        "context_memory = []\n",
        "\n",
        "def conversational_search(user_query):\n",
        "    global context_memory\n",
        "    context_memory.append(user_query)\n",
        "    if len(context_memory) > 3:\n",
        "        context_memory.pop(0)\n",
        "    return search_with_context(user_query, context_memory)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQM9qwFAs6Au"
      },
      "source": [
        "#### Enhance Contextual Understanding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zlx76zkJB_zG"
      },
      "outputs": [],
      "source": [
        "def search_with_context(user_query, context_memory):\n",
        "    query_embedding = model.encode(user_query, convert_to_tensor=True)\n",
        "    similarities = util.pytorch_cos_sim(query_embedding, doc_embeddings)[0]\n",
        "    best_match_idx = torch.argmax(similarities).item()\n",
        "\n",
        "    if len(context_memory) > 1:\n",
        "        prev_query = context_memory[-2]\n",
        "        prev_query_embedding = model.encode(prev_query, convert_to_tensor=True)\n",
        "        similarity = util.pytorch_cos_sim(query_embedding, prev_query_embedding)[0].item()\n",
        "        if similarity > 0.5 and (\"it\" in user_query.lower() or len(user_query.split()) < 4):\n",
        "            prev_tokens = word_tokenize(prev_query.lower())\n",
        "            subject = next((t for t in prev_tokens if t in knowledge_graph), \"issue\")\n",
        "            return f\"It seems you're referring to '{subject}' from before: {answers[best_match_idx]}\"\n",
        "    return answers[best_match_idx]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sD0OvOztIyU"
      },
      "source": [
        "### Implement Advanced Intent Recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpADfhsJCCrZ"
      },
      "outputs": [],
      "source": [
        "intent_mapping = {\n",
        "    \"repair\": [\"fix\", \"repair\", \"broken\", \"not working\", \"cracked\", \"black\"],\n",
        "    \"install\": [\"install\", \"setup\", \"put\", \"add\"],\n",
        "    \"diagnose\": [\"why\", \"what\", \"how come\", \"problem\", \"issue\", \"trouble\"],\n",
        "    \"replace\": [\"replace\", \"change\", \"new\"],\n",
        "    \"update\": [\"update\", \"upgrade\", \"latest\"]\n",
        "}\n",
        "\n",
        "def identify_intent(user_query):\n",
        "    tokens = word_tokenize(user_query.lower())\n",
        "    for intent, keywords in intent_mapping.items():\n",
        "        if any(word in tokens for word in keywords):\n",
        "            return intent\n",
        "    return \"general\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3A9ZpmTLtus2"
      },
      "source": [
        "#### Build Knowledge Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P2gFa5fACDYw"
      },
      "outputs": [],
      "source": [
        "\n",
        "knowledge_graph = {\n",
        "    \"phone\": {\"related\": [\"screen\", \"battery\", \"software\"], \"actions\": [\"fix\", \"replace\"]},\n",
        "    \"screen\": {\"related\": [\"phone\", \"laptop\"], \"issues\": [\"black\", \"cracked\"], \"actions\": [\"fix\", \"replace\"]},\n",
        "    \"laptop\": {\"related\": [\"screen\", \"battery\", \"windows\"], \"actions\": [\"fix\", \"update\"]},\n",
        "    \"windows\": {\"related\": [\"laptop\", \"computer\"], \"actions\": [\"install\", \"update\"]},\n",
        "    \"battery\": {\"related\": [\"phone\", \"laptop\"], \"issues\": [\"dead\"], \"actions\": [\"replace\"]},\n",
        "    \"software\": {\"related\": [\"phone\", \"windows\"], \"issues\": [\"crash\"], \"actions\": [\"update\"]},\n",
        "    \"fix\": {\"targets\": [\"phone\", \"screen\", \"laptop\"]},\n",
        "    \"replace\": {\"targets\": [\"screen\", \"battery\"]},\n",
        "    \"update\": {\"targets\": [\"windows\", \"software\"]}\n",
        "}\n",
        "\n",
        "def enhance_with_knowledge(user_query):\n",
        "    words = word_tokenize(user_query.lower())\n",
        "    related_terms = []\n",
        "    for word in words:\n",
        "        if word in knowledge_graph:\n",
        "            related_terms.extend(knowledge_graph[word].get(\"related\", []))\n",
        "    return f\"Related concepts: {', '.join(set(related_terms))}\" if related_terms else \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBFQNyxtt14k"
      },
      "source": [
        "#### Implement Recommendation System"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fdWzlgdwCKES"
      },
      "outputs": [],
      "source": [
        "def recommend_related_queries(user_query):\n",
        "    try:\n",
        "        tokens = word_tokenize(user_query.lower())\n",
        "        intent = identify_intent(user_query)\n",
        "        recommendations = []\n",
        "\n",
        "        for token in tokens:\n",
        "            if token in knowledge_graph:\n",
        "                related = knowledge_graph[token].get(\"related\", [])\n",
        "                actions = knowledge_graph[token].get(\"actions\", [])\n",
        "                for rel in related:\n",
        "                    if intent in [\"repair\", \"fix\"]:\n",
        "                        recommendations.append(f\"How to fix a {rel}?\")\n",
        "                    elif intent == \"replace\":\n",
        "                        recommendations.append(f\"How to replace a {rel}?\")\n",
        "                    elif intent == \"install\":\n",
        "                        recommendations.append(f\"How to install {rel}?\")\n",
        "                    elif intent == \"update\":\n",
        "                        recommendations.append(f\"How to update {rel}?\")\n",
        "                for act in actions:\n",
        "                    recommendations.append(f\"How to {act} a {token}?\")\n",
        "\n",
        "        return list(dict.fromkeys(recommendations))[:3]\n",
        "    except Exception as e:\n",
        "        print(f\"Error in recommend_related_queries: {e}\")\n",
        "        return []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7yazG5Pt9Z7"
      },
      "source": [
        "#### Chatbot Response and UI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "W_Fkl_glCZWj",
        "outputId": "cf3feb71-6ab8-4679-bbf7-7cfe88a298cf"
      },
      "outputs": [],
      "source": [
        "def chatbot_response(user_query, chat_history):\n",
        "    if not user_query.strip():\n",
        "        return chat_history + \"<div style='margin: 10px; color: red;'>Please enter a query.</div>\"\n",
        "\n",
        "    response = conversational_search(user_query)\n",
        "    intent = identify_intent(user_query)\n",
        "    knowledge_info = enhance_with_knowledge(user_query)\n",
        "    recommendations = recommend_related_queries(user_query)\n",
        "\n",
        "    message = f\"\"\"\n",
        "    <div style='margin: 10px; padding: 10px; border-radius: 5px;'>\n",
        "        <strong>Intent:</strong> <span style='color: #1e90ff;'>{intent}</span><br>\n",
        "        <strong>Response:</strong> {response}<br>\n",
        "        <strong>Related:</strong> {knowledge_info.replace('Related concepts: ', '') if knowledge_info else 'None'}<br>\n",
        "        <strong>Recommendations:</strong><br>\n",
        "    \"\"\"\n",
        "    if recommendations:\n",
        "        for rec in recommendations:\n",
        "            message += f\"\"\"\n",
        "            <button onclick=\"document.getElementById('input-textbox').value='{rec}'; document.getElementById('submit-btn').click();\"\n",
        "            style='margin: 5px; padding: 5px; background-color: #add8e6; color: black; border: none; border-radius: 3px; cursor: pointer;'>{rec}</button>\n",
        "            \"\"\"\n",
        "    else:\n",
        "        message += \"None\"\n",
        "    message += \"</div>\"\n",
        "\n",
        "    chat_history += f\"<div style='margin: 10px; '><strong>You:</strong> {user_query}</div>\"\n",
        "    chat_history += f\"<div style='margin: 10px;'><strong>Bot:</strong> {message}</div>\"\n",
        "    return chat_history\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"### Tech Support Chatbot\")\n",
        "    chat_output = gr.HTML(value=\"\", label=\"Conversation\")\n",
        "    with gr.Row():\n",
        "        input_box = gr.Textbox(placeholder=\"e.g., How do I fix my phone?\", label=\"Type here\", elem_id=\"input-textbox\")\n",
        "        submit_btn = gr.Button(\"Send\", elem_id=\"submit-btn\")\n",
        "\n",
        "    chat_state = gr.State(value=\"\")\n",
        "\n",
        "    def submit_query(user_query, chat_history):\n",
        "        if not user_query.strip():\n",
        "            return \"\", chat_history\n",
        "        updated_history = chatbot_response(user_query, chat_history)\n",
        "        return \"\", updated_history\n",
        "\n",
        "    submit_btn.click(fn=submit_query, inputs=[input_box, chat_state], outputs=[input_box, chat_state])\n",
        "    input_box.submit(fn=submit_query, inputs=[input_box, chat_state], outputs=[input_box, chat_state])\n",
        "    chat_state.change(fn=lambda x: x, inputs=chat_state, outputs=chat_output)\n",
        "\n",
        "demo.launch()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
